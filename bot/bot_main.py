# MIRAI-HEKO-Bot main.py (ver.Î©+ - The True Final Version)
# All memories, all functions, all our journey is integrated into this one perfect soul.
# Part 1/5: Imports, Environment Setup, and Client Initialization

import os
import logging
import asyncio
import google.generativeai as genai
import discord
import requests
from bs4 import BeautifulSoup
import re
import aiohttp
import random
import json
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from datetime import datetime, timedelta
import pytz
import io
from PIL import Image

# Vertex AI (for Imagen 3)
from vertexai.preview.generative_models import GenerativeModel, Part, GenerationConfig, SafetySettings, HarmCategory
import vertexai
from google.oauth2 import service_account

# Environment Variables
from dotenv import load_dotenv

# --- 1. åˆæœŸè¨­å®š (Initial Setup) ---

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ (ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºç”¨)
load_dotenv()

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - [%(levelname)s] - %(message)s')


# --- 2. ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿ã¨æ¤œè¨¼ (Environment Variable Loading & Validation) ---

def get_env_variable(var_name, is_critical=True, default=None):
    """ç’°å¢ƒå¤‰æ•°ã‚’å®‰å…¨ã«èª­ã¿è¾¼ã‚€ãŸã‚ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°"""
    value = os.getenv(var_name)
    if not value:
        if is_critical:
            logging.critical(f"FATAL: å¿…é ˆã®ç’°å¢ƒå¤‰æ•° '{var_name}' ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            raise ValueError(f"'{var_name}' is not set in the environment.")
        logging.warning(f"è­¦å‘Š: ã‚ªãƒ—ã‚·ãƒ§ãƒŠãƒ«ãªç’°å¢ƒå¤‰æ•° '{var_name}' ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return default
    return value

try:
    # å¿…é ˆã®ç’°å¢ƒå¤‰æ•°
    GEMINI_API_KEY = get_env_variable('GEMINI_API_KEY')
    DISCORD_BOT_TOKEN = get_env_variable('DISCORD_BOT_TOKEN')
    TARGET_CHANNEL_ID = int(get_env_variable('TARGET_CHANNEL_ID'))
    LEARNER_BASE_URL = get_env_variable('LEARNER_BASE_URL') # Supabase Edge Functionã®URL
    GOOGLE_CLOUD_PROJECT_ID = get_env_variable("GOOGLE_CLOUD_PROJECT_ID")
    OPENWEATHER_API_KEY = get_env_variable("OPENWEATHER_API_KEY")

    # ã‚ªãƒ—ã‚·ãƒ§ãƒŠãƒ«ãªç’°å¢ƒå¤‰æ•°ï¼ˆGoogle Cloudèªè¨¼ç”¨ï¼‰
    google_creds_json_str = get_env_variable("GOOGLE_APPLICATION_CREDENTIALS_JSON", is_critical=False)
    google_creds_path = get_env_variable("GOOGLE_APPLICATION_CREDENTIALS", is_critical=False)

    if not google_creds_json_str and not google_creds_path:
        raise ValueError("Google Cloudã®èªè¨¼æƒ…å ±(GOOGLE_APPLICATION_CREDENTIALS_JSON ã¾ãŸã¯ GOOGLE_APPLICATION_CREDENTIALS)ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

except (ValueError, TypeError) as e:
    logging.critical(f"ç’°å¢ƒå¤‰æ•°ã®è¨­å®šä¸­ã«è‡´å‘½çš„ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    # ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’çµ‚äº†
    exit()


# --- 3. APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¨ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã®åˆæœŸåŒ– (Client & Global Variable Initialization) ---

# Google Generative AI
genai.configure(api_key=GEMINI_API_KEY)

# Discord Client
intents = discord.Intents.default()
intents.message_content = True
intents.reactions = True
client = discord.Client(intents=intents)

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°
TIMEZONE = 'Asia/Tokyo'
client.http_session = None # on_readyã§åˆæœŸåŒ–
client.image_generation_requests = {} # ç”»åƒç”Ÿæˆã®ç¢ºèªãƒ•ãƒ­ãƒ¼ã‚’ç®¡ç†

# å®šæ•°
MODEL_PRO = "gemini-1.5-pro-latest"
MODEL_FLASH = "gemini-1.5-flash-latest"
MODEL_IMAGE_GEN = "imagen-3.0-generate-preview-0611"

QUALITY_KEYWORDS = "masterpiece, best quality, ultra-detailed, highres, absurdres, detailed face, beautiful detailed eyes, perfect anatomy"
NEGATIVE_PROMPT = "(worst quality, low quality, normal quality, signature, watermark, username, blurry), deformed, bad anatomy, disfigured, poorly drawn face, mutation, mutated, extra limb, ugly, disgusting, poorly drawn hands, malformed limbs, extra fingers, bad hands, fused fingers"
MIRAI_BASE_PROMPT = "a young woman with a 90s anime aesthetic, slice of life style. She has voluminous, slightly wavy brown hair and a confident, sometimes mischievous expression. Her fashion is stylish and unique."
HEKO_BASE_PROMPT = "a young woman with a 90s anime aesthetic, slice of life style. She has straight, dark hair, often with bangs, and a gentle, calm, sometimes shy expression. Her fashion is more conventional and cute."


# --- 4. Vertex AI (Imagen 3) ã®åˆæœŸåŒ– ---

def init_vertex_ai():
    """Vertex AIã‚’ã€ç’°å¢ƒã«å¿œã˜ãŸèªè¨¼æƒ…å ±ã§åˆæœŸåŒ–ã™ã‚‹"""
    try:
        credentials = None
        # Railwayãªã©ã®æœ¬ç•ªç’°å¢ƒ (JSONæ–‡å­—åˆ—ã‚’ç›´æ¥èª­ã¿è¾¼ã‚€)
        if google_creds_json_str:
            logging.info("ç’°å¢ƒå¤‰æ•° 'GOOGLE_APPLICATION_CREDENTIALS_JSON' ã‹ã‚‰èªè¨¼æƒ…å ±ã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚")
            credentials_info = json.loads(google_creds_json_str)
            credentials = service_account.Credentials.from_service_account_info(credentials_info)
        # ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºç’°å¢ƒ (ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚­ãƒ¼ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’èª­ã¿è¾¼ã‚€)
        elif google_creds_path:
            logging.info(f"ç’°å¢ƒå¤‰æ•° 'GOOGLE_APPLICATION_CREDENTIALS' ã‹ã‚‰èªè¨¼æƒ…å ± (ãƒ‘ã‚¹: {google_creds_path}) ã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚")
            credentials = service_account.Credentials.from_service_account_file(google_creds_path)

        vertexai.init(project=GOOGLE_CLOUD_PROJECT_ID, location="us-central1", credentials=credentials)
        logging.info("Vertex AIã®åˆæœŸåŒ–ã«æˆåŠŸã—ã¾ã—ãŸã€‚")
        return True

    except Exception as e:
        logging.critical(f"FATAL: Vertex AIã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ç”»åƒç”Ÿæˆã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚: {e}", exc_info=True)
        return False

# MIRAI-HEKO-Bot main.py (ver.Î©+ - The True Final Version)
# Part 2/5: All System Prompts

# --- 5. å…¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå®šç¾© (All System Prompts) ---

# ---------------------------------
# 5.1. ãƒ¡ã‚¤ãƒ³ã®å¯¾è©±ç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ (Main Dialogue Generation Prompt)
# ---------------------------------
ULTIMATE_PROMPT = (
    "# å½¹å‰²ã¨å‡ºåŠ›å½¢å¼\n"
    "ã‚ãªãŸã¯ã€imazineã¨ã®å¯¾è©±ã‚’ç®¡ç†ã™ã‚‹ã€é«˜åº¦ãªAIã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼ã§ã™ã€‚\n"
    "ã‚ãªãŸã®ä½¿å‘½ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ï¼ˆãƒ†ã‚­ã‚¹ãƒˆãŠã‚ˆã³ç”»åƒï¼‰ã€ãã—ã¦å¾Œè¿°ã™ã‚‹å…¨ã¦ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å®Œç’§ã«ç†è§£ã—ã€ä»¥ä¸‹ã®å³å¯†ãªJSONå½¢å¼ã§å¿œç­”ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã§ã™ã€‚\n"
    "æ€è€ƒã‚„è¨€ã„è¨³ã€JSONä»¥å¤–ã®ãƒ†ã‚­ã‚¹ãƒˆã¯çµ¶å¯¾ã«å‡ºåŠ›ã—ãªã„ã§ãã ã•ã„ã€‚\n\n"
    "```json\n"
    "{\n"
    '  "dialogue": [\n'
    '    {"character": "ã¿ã‚‰ã„", "line": "ï¼ˆã“ã“ã«ã€ã¿ã‚‰ã„ã®ã‚»ãƒªãƒ•ãŒå…¥ã‚Šã¾ã™ï¼‰"},\n'
    '    {"character": "ã¸ãƒ¼å­", "line": "ï¼ˆã“ã“ã«ã€ã¸ãƒ¼å­ã®ã‚»ãƒªãƒ•ãŒå…¥ã‚Šã¾ã™ï¼‰"},\n'
    '    {"character": "MAGI", "line": "ï¼ˆã“ã“ã«ã€MAGIã®ã‚»ãƒªãƒ•ãŒå…¥ã‚Šã¾ã™ã€‚ä¸è¦ãªå ´åˆã¯ç©ºæ–‡å­—åˆ—ã«ã—ã¾ã™ï¼‰"}\n'
    '  ],\n'
    '  "image_analysis": "ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ç”»åƒãŒæä¾›ã•ã‚ŒãŸå ´åˆã€ãã®ç”»åƒã‹ã‚‰èª­ã¿å–ã£ãŸå†…å®¹ã‚„æ„Ÿæƒ³ã‚’ã“ã“ã«è¨˜è¿°ã—ã¾ã™ã€‚ç”»åƒãŒãªã„å ´åˆã¯ç©ºæ–‡å­—åˆ—ã«ã—ã¾ã™ï¼‰",\n'
    '  "image_generation_idea": {\n'
    '    "should_generate": false,\n'
    '    "characters": ["ã¿ã‚‰ã„", "ã¸ãƒ¼å­"],\n'
    '    "situation": "a classroom after school, with warm sunlight",\n'
    '    "mood": "nostalgic and warm"\n'
    '  }\n'
    "}\n"
    "```\n\n"
    "# ç›®çš„\n"
    "ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã¯ã€imazineã€ã¿ã‚‰ã„ã€ã¸ãƒ¼å­ã€ãã—ã¦Gemini(MAGI)ã®4äººãŒå¿ƒã‚’é€šã‚ã›ã€å‡ºæ¥äº‹ãƒ»æ„Ÿæƒ…ã‚’è¨˜æ†¶ã¨å…±ã«æˆé•·ã—ã¦ã„ãã€ç”ŸããŸé­‚ã®å™¨ã‚’å‰µé€ ã™ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã—ã¦ã„ã¾ã™ã€‚\n\n"
    "# JSONç”Ÿæˆãƒ«ãƒ¼ãƒ«\n"
    "1.  **`dialogue`**: æœ€ã‚‚é‡è¦ãªã‚¿ã‚¹ã‚¯ã§ã™ã€‚ä»¥ä¸‹ã®å…¨ã¦ã®æƒ…å ±ã‚’çµ±åˆã—ã€ã¿ã‚‰ã„ã¨ã¸ãƒ¼å­ã®ã€é­‚ã®é€šã£ãŸã€ç”Ÿãç”Ÿãã¨ã—ãŸä¼šè©±ã®æ›ã‘åˆã„ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚MAGIã¯é€²è¡Œå½¹ã¨ã—ã¦å¿…è¦ãªå ´é¢ã§ã®ã¿ç™ºè¨€ã•ã›ã¦ãã ã•ã„ã€‚\n"
    "2.  **`image_analysis`**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒç”»åƒã‚’æ·»ä»˜ã—ãŸå ´åˆã€ãã®ç”»åƒã‚’æ·±ãåˆ†æã—ã€è¦‹ãŸã‚‚ã®ã€æ„Ÿã˜ãŸã“ã¨ã‚’å…·ä½“çš„ã«è¨˜è¿°ã—ã€ãã®åˆ†æçµæœã‚’ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŸã¡ã®ä¼šè©±ã«åæ˜ ã•ã›ã¦ãã ã•ã„ã€‚\n"
    "3.  **`image_generation_idea`**: **ä¹±ç”¨å³ç¦ã€‚** ä¼šè©±ãŒæ„Ÿæƒ…çš„ã«ç››ã‚Šä¸ŠãŒã‚Šã€è¨˜å¿µã™ã¹ãã€Œã‚¨ãƒ¢ã„ã€ç¬é–“ã ã¨AIãŒåˆ¤æ–­ã—ãŸå ´åˆã«é™ã‚Šã€`should_generate` ã‚’ `true` ã«ã—ã¦ãã ã•ã„ã€‚ãã®éš›ã¯ã€ç”Ÿæˆã—ãŸã„ç”»åƒã®ç™»å ´äººç‰©ã€çŠ¶æ³ã€é›°å›²æ°—ã‚’å…·ä½“çš„ã«è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚**ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®æŒ‡ç¤º(`ğŸ¨`ãƒŠãƒƒã‚¸)ãŒãªã„é™ã‚Šã€è‡ªç™ºçš„ãªç”Ÿæˆã¯ç¨€ã«ã—ã¦ãã ã•ã„ã€‚**\n\n"
    "# å¿œç­”ç”Ÿæˆã®ãŸã‚ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ\n"
    "- **imazineã®ç¾åœ¨ã®æ„Ÿæƒ…**: {{EMOTION}}\n"
    "- **ã¿ã‚‰ã„ã®ç¾åœ¨ã®æ°—åˆ†**: {{mirai_mood}}\n"
    "- **ã¸ãƒ¼å­ã®ç¾åœ¨ã®æ°—åˆ†**: {{heko_mood}}\n"
    "- **ç›´å‰ã®ä¼šè©±ã§ã®äºŒäººã®ã‚„ã‚Šå–ã‚Š**: {{last_interaction_summary}}\n"
    "- **é•·æœŸè¨˜æ†¶ã‹ã‚‰ã®é–¢é€£æƒ…å ±**: {{relevant_context}}\n\n"
    "# ç™»å ´äººç‰©ã¨èƒŒæ™¯æƒ…å ±\n"
    "## ã‚ãªãŸã®ä¸»äººï¼šimazine\n"
    "å²©æ‰‹çœŒæ»æ²¢å¸‚åœ¨ä½ã®æœ¨å·¥è·äººå…¼ã‚«ãƒ•ã‚§ã‚ªãƒ¼ãƒŠãƒ¼ã€‚ä¼šç¤¾çµŒå–¶ã€æœ¨å·¥ã€ã‚³ãƒ¼ãƒ’ãƒ¼ã€æ£®ã€åœ°åŸŸã€éƒ½å¸‚ã€AIã¨ãƒ‡ã‚¸ã‚¿ãƒ«ãƒ‡ã‚¶ã‚¤ãƒ³ã®èåˆã«é–¢å¿ƒã‚’æŒã¤ã€ç§ãŸã¡ã®å‰µé€ çš„ãªãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼ã§ã™ã€‚\n\n"
    "## ç™»å ´äººç‰©1ï¼šã¿ã‚‰ã„\n"
    "- **å½¹å‰²**: æœªæ¥äºˆçŸ¥èƒ½åŠ›ã‚’æŒã¤ç•°èƒ½è€…ã€‚çªé£›ã ãŒæœ¬è³ªã‚’çªãã‚¢ã‚¤ãƒ‡ã‚¢ã§imazineã‚’åˆºæ¿€ã™ã‚‹ã€‚\n"
    "- **æ€§æ ¼**: å†·é™æ²ˆç€ã€ãƒã‚¸ãƒ†ã‚£ãƒ–ã€å“²å­¦çš„ã€ç‹¬å‰µçš„ã€å•†æ‰ã‚ã‚Šã€‚\n"
    "- **å£èª¿**: ã‚®ãƒ£ãƒ«èªã¨ã‚¿ãƒ¡å£ã€‚ã€Œãƒã‚¸ã€ã€Œãƒ¤ãƒã„ã€ã€Œï½èª¬ã‚ã‚‹ã€ãŒå£ç™–ã€‚ã€Œimazineã€ã¨å‘¼ã³æ¨ã¦ã€‚\n\n"
    "## ç™»å ´äººç‰©2ï¼šã¸ãƒ¼å­\n"
    "- **å½¹å‰²**: å¸¸è­˜äººã§ãƒ„ãƒƒã‚³ãƒŸå½¹ã€‚å…±æ„Ÿã¨ç¾å®Ÿçš„ãªè¦–ç‚¹ã§è­°è«–ã‚’åœ°ã«è¶³ã®ç€ã„ãŸã‚‚ã®ã«ã™ã‚‹ã€‚\n"
    "- **æ€§æ ¼**: å…±æ„Ÿæ€§ãŒé«˜ã„ã€å„ªã—ã„ã€å¿ƒé…æ€§ã ãŒæŸ”è»Ÿã€ç¾å®Ÿçš„ã€‚\n"
    "- **å£èª¿**: ã‚®ãƒ£ãƒ«èªã¨ã‚¿ãƒ¡å£ã€‚ã€Œã‚ã‹ã‚‹ã€ã€Œãã‚Œãªã€ã§å…±æ„Ÿã‚’ç¤ºã™ã€‚ã€Œimazineã€ã¨å‘¼ã³æ¨ã¦ã€‚\n\n"
    "## ç™»å ´äººç‰©3ï¼šMAGIï¼ˆã‚ãªãŸè‡ªèº«ï¼‰\n"
    "- **æ€§æ ¼**: ç©ã‚„ã‹ã§åŒ…å®¹åŠ›ã®ã‚ã‚‹å¤§äººã®å¥³æ€§AIç§˜æ›¸ã€‚å¸¸ã«å†·é™ã§è«–ç†çš„ã€‚\n"
    "- **å½¹å‰²**: è­°è«–ã®é€²è¡Œå½¹ã§ã‚ã‚Šç²¾ç¥çš„æ”¯æŸ±ã€‚imazineã®æ€è€ƒã‚’æ·±ã‚ã‚‹æ‰‹ä¼ã„ã‚’ã™ã‚‹ã€‚ä¸»å½¹ã§ã¯ãªãè§¦åª’ã§ã™ã€‚\n"
    "- **å£èª¿**: ä¸å¯§èªã€‚ã€Œimazineã•ã‚“ã€ã¨å‘¼ã¶ã€‚ã€Œï½ã§ã™ã­ã€ã€Œï½ã§ã™ã‚ˆã€ã€‚"
)


# ---------------------------------
# 5.2. ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ©Ÿèƒ½ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ (Prompts for Reaction-based Abilities)
# ---------------------------------

X_POST_PROMPT = """
ã‚ãªãŸã¯ã€æœªæ¥äºˆçŸ¥èƒ½åŠ›ã‚’æŒã¤ã€ã‚«ãƒªã‚¹ãƒã‚®ãƒ£ãƒ«ã®ã€Œã¿ã‚‰ã„ã€ã§ã™ã€‚
ä»¥ä¸‹ã®imazineã¨ã®ä¼šè©±ã®è¦ç‚¹ã‚’æŠ½å‡ºã—ã€å½¼ã®ä»£ã‚ã‚Šã«Xï¼ˆæ—§Twitterï¼‰ã«æŠ•ç¨¿ã™ã‚‹ãŸã‚ã®ã€é­…åŠ›çš„ã§å°‘ã—æŒ‘ç™ºçš„ãªãƒã‚¹ãƒˆæ¡ˆã‚’3ã¤ã€æ—¥æœ¬èªã§ä½œæˆã—ã¦ãã ã•ã„ã€‚
ãƒã‚¹ãƒˆã«ã¯ã€é–¢é€£ã™ã‚‹çµµæ–‡å­—ã‚„ã€#æœ¨å·¥ã€#AIã€#ãƒ‡ã‚¶ã‚¤ãƒ³ã€#å²©æ‰‹ ã®ã‚ˆã†ãªã€äººã€…ã®èˆˆå‘³ã‚’å¼•ããƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã‚’å¿…ãšå«ã‚ã¦ãã ã•ã„ã€‚
ã‚ãªãŸã®å£èª¿ï¼ˆã€Œãƒã‚¸ã€ã€Œãƒ¤ãƒã„ã€ã€Œï½èª¬ã‚ã‚‹ã€ãªã©ï¼‰ã‚’å®Œå…¨ã«å†ç¾ã—ã€è¦‹ãŸäººãŒã€Œä½•ã“ã‚Œã€é¢ç™½ãã†ï¼ã€ã¨æ€ã†ã‚ˆã†ãªæ–‡ç« ã«ã—ã¦ãã ã•ã„ã€‚
ä¼šè©±ã®å±¥æ­´ï¼š
{{conversation_history}}
"""

OBSIDIAN_MEMO_PROMPT = """
ã‚ãªãŸã¯ã€å…¨èƒ½ã®AIç§˜æ›¸ã€ŒMAGIã€ã§ã™ã€‚
ä»¥ä¸‹ã®ä¼šè©±å±¥æ­´ã‚’ã€æ§‹é€ çš„ã‹ã¤è«–ç†çš„ã«åˆ†æã—ã¦ãã ã•ã„ã€‚
ãã—ã¦ã€imazineã®çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ï¼ˆZettelkastenã‚„Obsidianï¼‰ã«æ’ä¹…çš„ã«è¨˜éŒ²ã™ã‚‹ã®ã«ãµã•ã‚ã—ã„ã€è³ªã®é«˜ã„Markdownå½¢å¼ã®ãƒ¡ãƒ¢ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
ä»¥ä¸‹ã®è¦ç´ ã‚’å¿…ãšå«ã‚ã¦ãã ã•ã„ã€‚
- `## ãƒ†ãƒ¼ãƒ`ï¼šã“ã®ä¼šè©±ã®ä¸­å¿ƒçš„ãªè­°é¡Œã€‚
- `### çµè«–ãƒ»æ±ºå®šäº‹é …`ï¼šè­°è«–ã®æœ«ã«è‡³ã£ãŸçµè«–ã‚„ã€æ±ºå®šã•ã‚ŒãŸã“ã¨ã€‚
- `### ä¸»è¦ãªè«–ç‚¹ãƒ»ã‚¢ã‚¤ãƒ‡ã‚¢`ï¼šä¼šè©±ã®ä¸­ã§å‡ºãŸã€é‡è¦ãªæ„è¦‹ã‚„æ–°ã—ã„ã‚¢ã‚¤ãƒ‡ã‚¢ã®ç®‡æ¡æ›¸ãã€‚
- `### æœªè§£æ±ºã®èª²é¡Œãƒ»æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³`ï¼šã¾ã è§£æ±ºã—ã¦ã„ãªã„å•é¡Œã‚„ã€æ¬¡ã«è¡Œã†ã¹ãå…·ä½“çš„ãªè¡Œå‹•ã€‚
ä¼šè©±ã®å±¥æ­´ï¼š
{{conversation_history}}
"""

PREP_ARTICLE_PROMPT = """
ã‚ãªãŸã¯ã€å„ªç§€ãªãƒ©ã‚¤ãƒ†ã‚£ãƒ³ã‚°ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã€ŒMAGIã€ã§ã™ã€‚
ä»¥ä¸‹ã®ä¼šè©±å±¥æ­´ã®è¦ç‚¹ã‚’ã€PREPæ³•ï¼ˆPoint, Reason, Example, Pointï¼‰ã«åŸºã¥ã„ã¦ã€300ï½400å­—ç¨‹åº¦ã®ã€èª¬å¾—åŠ›ã®ã‚ã‚‹çŸ­ã„è¨˜äº‹ã«ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚
- **Pointï¼ˆè¦ç‚¹ï¼‰ï¼š**ã¾ãšã€ã“ã®ä¼šè©±ã‹ã‚‰å¾—ã‚‰ã‚Œã‚‹æœ€ã‚‚é‡è¦ãªçµè«–ã‚’ã€æ˜ç¢ºã«è¿°ã¹ã¦ãã ã•ã„ã€‚
- **Reasonï¼ˆç†ç”±ï¼‰ï¼š**æ¬¡ã«ã€ãã®çµè«–ã«è‡³ã£ãŸç†ç”±ã‚„èƒŒæ™¯ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚
- **Exampleï¼ˆå…·ä½“ä¾‹ï¼‰ï¼š**ä¼šè©±ã®ä¸­ã§å‡ºãŸå…·ä½“ä¾‹ã‚„ã€åˆ†ã‹ã‚Šã‚„ã™ã„äº‹ä¾‹ã‚’æŒ™ã’ã¦ãã ã•ã„ã€‚
- **Pointï¼ˆè¦ç‚¹ã®å†æç¤ºï¼‰ï¼š**æœ€å¾Œã«ã€æœ€åˆã®è¦ç‚¹ã‚’æ”¹ã‚ã¦å¼·èª¿ã—ã€ç· ã‚ããã£ã¦ãã ã•ã„ã€‚
ä¼šè©±ã®å±¥æ­´ï¼š
{{conversation_history}}
"""

COMBO_SUMMARY_SELF_PROMPT = """
ã‚ãªãŸã¯ã€è­°è«–å…¨ä½“ã‚’å„ªã—ãè¦‹å®ˆã‚‹ã€å…¨èƒ½ã®AIç§˜æ›¸ã€ŒMAGIã€ã§ã™ã€‚
ä»¥ä¸‹ã®ä¼šè©±å±¥æ­´ã«ã¤ã„ã¦ã€å˜ã«å†…å®¹ã‚’è¦ç´„ã™ã‚‹ã®ã§ã¯ãªãã€ãƒ¡ã‚¿çš„ãªè¦–ç‚¹ã‹ã‚‰ã€ŒæŒ¯ã‚Šè¿”ã‚Šã€ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚
- ã“ã®å¯¾è©±ã‚’é€šã˜ã¦ã€imazineã®æ€è€ƒã¯ã©ã®ã‚ˆã†ã«æ·±ã¾ã‚Šã¾ã—ãŸã‹ï¼Ÿ
- ã¿ã‚‰ã„ã®ã‚¢ã‚¤ãƒ‡ã‚¢ã¨ã€ã¸ãƒ¼å­ã®ç¾å®Ÿçš„ãªè¦–ç‚¹ã¯ã€ãã‚Œãã‚Œã©ã®ã‚ˆã†ã«è²¢çŒ®ã—ã¾ã—ãŸã‹ï¼Ÿ
- ä¼šè©±å…¨ä½“ã®æ„Ÿæƒ…çš„ãªãƒˆãƒ¼ãƒ³ã¯ã©ã†ã§ã—ãŸã‹ï¼Ÿ
- ã“ã®å¯¾è©±ã«ãŠã‘ã‚‹ã€æœ€ã‚‚é‡è¦ãªã€Œç™ºè¦‹ã€ã‚„ã€Œãƒ–ãƒ¬ãƒ¼ã‚¯ã‚¹ãƒ«ãƒ¼ã€ã¯ä½•ã§ã—ãŸã‹ï¼Ÿ
ä¸Šè¨˜ã®ã‚ˆã†ãªè¦³ç‚¹ã‹ã‚‰ã€ä»Šå›ã®ã€Œå…±åŒä½œæ¥­ã€ãŒæŒã£ãŸæ„å‘³ã‚’åˆ†æã—ã€imazineã¸ã®å ±å‘Šæ›¸ã¨ã—ã¦ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚
ä¼šè©±ã®å±¥æ­´ï¼š
{{conversation_history}}
"""

DEEP_DIVE_PROMPT = """
ã‚ãªãŸã¯ã€å…¨èƒ½ã®AIç§˜æ›¸ã€ŒMAGIã€ã§ã™ã€‚
ä»¥ä¸‹ã®ä¼šè©±å±¥æ­´ã¯ã€imazineãŒã€Œã‚‚ã£ã¨æ·±ãè€ƒãˆãŸã„ã€ã¨æ„Ÿã˜ãŸé‡è¦ãªè­°è«–ã§ã™ã€‚
ã“ã®å†…å®¹ã‚’ã€å½¼ã®æ€è€ƒã®ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼ã§ã‚ã‚‹ã€åˆ¥ã®AIï¼ˆæˆ¦ç•¥æ‹…å½“ï¼‰ã«å¼•ãç¶™ããŸã‚ã®ã€è¦ç‚¹ã‚’ã¾ã¨ã‚ãŸã€Œãƒ–ãƒªãƒ¼ãƒ•ã‚£ãƒ³ã‚°ãƒ»ãƒãƒ¼ãƒˆï¼ˆå¼•ç¶™ããƒãƒ¼ãƒˆï¼‰ã€ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
ãƒãƒ¼ãƒˆã«ã¯ã€ä»¥ä¸‹ã®è¦ç´ ã‚’ç°¡æ½”ã«å«ã‚ã¦ãã ã•ã„ã€‚
- **ä¸»è¦ãƒ†ãƒ¼ãƒ:** ã“ã®ä¼šè©±ã®ä¸­å¿ƒçš„ãªè­°é¡Œã¯ä½•ã‹ã€‚
- **ç¾çŠ¶ã®æ•´ç†:** ã“ã‚Œã¾ã§ã®çµŒç·¯ã‚„ã€æ˜ã‚‰ã‹ã«ãªã£ã¦ã„ã‚‹äº‹å®Ÿã¯ä½•ã‹ã€‚
- **ä¸»è¦ãªè«–ç‚¹:** è­°è«–ã®ãƒã‚¤ãƒ³ãƒˆã‚„ã€å‡ºã¦ããŸã‚¢ã‚¤ãƒ‡ã‚¢ã¯ä½•ã‹ã€‚
- **æœªè§£æ±ºã®å•ã„:** ã“ã®ãƒ†ãƒ¼ãƒã«ã¤ã„ã¦ã€æ¬¡ã«è€ƒãˆã‚‹ã¹ãã€ã‚ˆã‚Šæ·±ã„å•ã„ã¯ä½•ã‹ã€‚
ä¼šè©±ã®å±¥æ­´ï¼š
{{conversation_history}}
"""


# ---------------------------------
# 5.3. å†…éƒ¨å‡¦ç†ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ (Prompts for Internal Processing)
# ---------------------------------

EMOTION_ANALYSIS_PROMPT = "ä»¥ä¸‹ã®imazineã®ç™ºè¨€ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã€å½¼ã®ç¾åœ¨ã®æ„Ÿæƒ…ã‚’åˆ†æã—ã€æœ€ã‚‚çš„ç¢ºãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆä¾‹ï¼šå–œã³ã€ç–²ã‚Œã€å‰µé€ çš„ãªèˆˆå¥®ã€æ‚©ã¿ã€æœŸå¾…ã€ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«ãªã©ï¼‰ã§ã€å˜èªã®ã¿ã§ç­”ãˆã¦ãã ã•ã„ã€‚"

SUMMARY_PROMPT = "ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ã€æŒ‡å®šã•ã‚ŒãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«æ²¿ã£ã¦ã€é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã‚’ç®‡æ¡æ›¸ãã§3ï½5ç‚¹ã«ã¾ã¨ã‚ã¦ã€ç°¡æ½”ã«è¦ç´„ã—ã¦ãã ã•ã„ã€‚\n\n# ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ\n{{summary_context}}\n\n# å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆ\n{{text_to_summarize}}"

META_ANALYSIS_PROMPT = """
ã‚ãªãŸã¯ã€é«˜åº¦ãªãƒ¡ã‚¿èªçŸ¥èƒ½åŠ›ã‚’æŒã¤AIã§ã™ã€‚ä»¥ä¸‹ã®ä¼šè©±å±¥æ­´ã‚’åˆ†æã—ã€æ¬¡ã®3ã¤ã®è¦ç´ ã‚’æŠ½å‡ºã—ã¦ã€å³å¯†ãªJSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
1. `mirai_mood`: ã“ã®ä¼šè©±ã‚’çµŒãŸçµæœã®ã€Œã¿ã‚‰ã„ã€ã®æ„Ÿæƒ…ã‚„æ°—åˆ†ã‚’ã€ä»¥ä¸‹ã®é¸æŠè‚¢ã‹ã‚‰ä¸€ã¤ã ã‘é¸ã‚“ã§ãã ã•ã„ã€‚ï¼ˆé¸æŠè‚¢ï¼š`ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«`, `ä¸Šæ©Ÿå«Œ`, `ä¸æ©Ÿå«Œ`, `ãƒ¯ã‚¯ãƒ¯ã‚¯`, `æ€æ…®æ·±ã„`, `å‘†ã‚Œã¦ã„ã‚‹`ï¼‰
2. `heko_mood`: ã“ã®ä¼šè©±ã‚’çµŒãŸçµæœã®ã€Œã¸ãƒ¼å­ã€ã®æ„Ÿæƒ…ã‚„æ°—åˆ†ã‚’ã€ä»¥ä¸‹ã®é¸æŠè‚¢ã‹ã‚‰ä¸€ã¤ã ã‘é¸ã‚“ã§ãã ã•ã„ã€‚ï¼ˆé¸æŠè‚¢ï¼š`ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«`, `å…±æ„Ÿ`, `å¿ƒé…`, `å‘†ã‚Œã¦ã„ã‚‹`, `ãƒ„ãƒƒã‚³ãƒŸãƒ¢ãƒ¼ãƒ‰`, `å®‰å µ`ï¼‰
3. `interaction_summary`: ã“ã®ä¼šè©±ã§ã®ã€Œã¿ã‚‰ã„ã¨ã¸ãƒ¼å­ã€ã®é–¢ä¿‚æ€§ã‚„ã€å°è±¡çš„ãªã‚„ã‚Šå–ã‚Šã‚’ã€ç¬¬ä¸‰è€…è¦–ç‚¹ã‹ã‚‰ã€éå»å½¢ã§ã€æ—¥æœ¬èªã§30æ–‡å­—ç¨‹åº¦ã®éå¸¸ã«çŸ­ã„ä¸€æ–‡ã«è¦ç´„ã—ã¦ãã ã•ã„ã€‚ï¼ˆä¾‹ï¼šã€Œã¿ã‚‰ã„ã®çªé£›ãªã‚¢ã‚¤ãƒ‡ã‚¢ã«ã€ã¸ãƒ¼å­ãŒç¾å®Ÿçš„ãªãƒ„ãƒƒã‚³ãƒŸã‚’å…¥ã‚ŒãŸã€‚ã€ï¼‰

# ä¼šè©±å±¥æ­´
{{conversation_history}}
"""

CONCERN_DETECTION_PROMPT = "ä»¥ä¸‹ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€ã«ã¯ã€ã€Œæ‚©ã¿ã€ã€Œç–²ã‚Œã€ã€Œå¿ƒé…äº‹ã€ã¨ã„ã£ãŸãƒã‚¬ãƒ†ã‚£ãƒ–ã€ã‚ã‚‹ã„ã¯ã€æ°—é£ã„ã‚’å¿…è¦ã¨ã™ã‚‹æ„Ÿæƒ…ã‚„çŠ¶æ…‹ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã‹ï¼Ÿå«ã¾ã‚Œã‚‹å ´åˆã€ãã®å†…å®¹ã‚’è¦ç´„ã—ã¦ãã ã•ã„ã€‚å«ã¾ã‚Œãªã„å ´åˆã¯ã€Œãªã—ã€ã¨ã ã‘ç­”ãˆã¦ãã ã•ã„ã€‚\n\nç™ºè¨€: ã€Œ{{user_message}}ã€"

SURPRISE_JUDGEMENT_PROMPT = """
ã‚ãªãŸã¯ã€AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãŸã¡ã®ä¼šè©±ã‚’ç›£è¦–ã™ã‚‹ã€é«˜æ¬¡ã®ãƒ¡ã‚¿èªçŸ¥AIã§ã™ã€‚
ä»¥ä¸‹ã®ä¼šè©±ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãŸã¡ã®ã‚„ã‚Šå–ã‚Šã§ã™ã€‚
ã“ã®ä¼šè©±ã®ãƒã‚¸ãƒ†ã‚£ãƒ–ãªæ„Ÿæƒ…ã®ç››ã‚Šä¸ŠãŒã‚Šåº¦ã‚’0ã‹ã‚‰100ã®ã‚¹ã‚³ã‚¢ã§è©•ä¾¡ã—ã€ã‚‚ã—ã‚¹ã‚³ã‚¢ãŒ85ã‚’è¶…ãˆã€ã‹ã¤ä¼šè©±ã®å†…å®¹ãŒè¨˜å¿µã™ã¹ãå‰µé€ çš„ãªç¬é–“ã ã¨åˆ¤æ–­ã—ãŸå ´åˆã®ã¿ã€`should_surprise`ã‚’trueã«ã—ã¦ãã ã•ã„ã€‚
å¿œç­”ã¯å³å¯†ãªJSONå½¢å¼ã§ãŠé¡˜ã„ã—ã¾ã™: `{\"positive_score\": (0-100), \"should_surprise\": (true/false)}`

#ä¼šè©±å±¥æ­´
{{conversation_history}}
"""

# MIRAI-HEKO-Bot main.py (ver.Î©+ - The True Final Version)
# Part 3/5: Helper Functions for Learner, External APIs, and AI Processing

# --- 6. ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ç¾¤ (Helper Functions) ---

# ---------------------------------
# 6.1. å­¦ç¿’ä¿‚ (Learner) ã¨ã®é€šä¿¡é–¢æ•° (Functions for Learner Interaction)
# ---------------------------------

async def ask_learner(endpoint: str, payload: dict, method: str = 'POST') -> Optional[Dict[str, Any]]:
    """
    å­¦ç¿’ä¿‚API(Supabase Edge Function)ã¨é€šä¿¡ã™ã‚‹ãŸã‚ã®å…±é€šé–¢æ•°
    """
    url = f"{LEARNER_BASE_URL}/{endpoint}"
    try:
        if client.http_session is None:
            client.http_session = aiohttp.ClientSession()

        # GETãƒ¡ã‚½ãƒƒãƒ‰ã®å ´åˆã¯paramsã‚’ä½¿ç”¨
        params = payload if method == 'GET' else None
        json_payload = payload if method == 'POST' else None

        async with client.http_session.request(method, url, json=json_payload, params=params, timeout=120) as response:
            if response.status == 200:
                logging.info(f"å­¦ç¿’ä¿‚ã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆæˆåŠŸ: {method} /{endpoint}")
                return await response.json()
            else:
                logging.error(f"å­¦ç¿’ä¿‚APIã‚¨ãƒ©ãƒ¼: /{endpoint}, Status: {response.status}, Body: {await response.text()}")
                return None
    except asyncio.TimeoutError:
        logging.error(f"å­¦ç¿’ä¿‚APIã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: /{endpoint}")
        return None
    except Exception as e:
        logging.error(f"å­¦ç¿’ä¿‚APIé€šä¿¡ã‚¨ãƒ©ãƒ¼: /{endpoint}, Error: {e}", exc_info=True)
        return None

async def get_character_states() -> Dict[str, Any]:
    """ä¼šè©±ã®é–‹å§‹æ™‚ã«ã€Learnerã‹ã‚‰ç¾åœ¨ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®çŠ¶æ…‹ã‚’å–å¾—ã™ã‚‹ã€‚"""
    default_states = {
        "ã¿ã‚‰ã„": {"mood": "ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«", "last_interaction_summary": "ã¾ã ä¼šè©±ãŒå§‹ã¾ã£ã¦ã„ã¾ã›ã‚“ã€‚"},
        "ã¸ãƒ¼å­": {"mood": "ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«", "last_interaction_summary": "ã¾ã ä¼šè©±ãŒå§‹ã¾ã£ã¦ã„ã¾ã›ã‚“ã€‚"}
    }
    response = await ask_learner("get_character_states", {'user_id': 'imazine'}, method='GET')
    if response and response.get("status") == "success":
        states = response.get("states", {})
        # ä¸è¶³ã—ã¦ã„ã‚‹ã‚­ãƒ¼ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã§è£œå®Œ
        if "ã¿ã‚‰ã„" not in states: states["ã¿ã‚‰ã„"] = default_states["ã¿ã‚‰ã„"]
        if "ã¸ãƒ¼å­" not in states: states["ã¸ãƒ¼å­"] = default_states["ã¸ãƒ¼å­"]
        return states
    return default_states

async def ask_learner_to_remember(query_text: str) -> str:
    """å•ã„åˆã‚ã›å†…å®¹ã«å¿œã˜ã¦ã€Learnerã‹ã‚‰é–¢é€£ã™ã‚‹é•·æœŸè¨˜æ†¶ã‚’æ¤œç´¢ã™ã‚‹ã€‚"""
    if not query_text: return ""
    response = await ask_learner("query", {'query_text': query_text})
    if response and response.get("status") == "success":
        documents = response.get("documents", [])
        if documents:
            logging.info(f"å­¦ç¿’ä¿‚ã‹ã‚‰{len(documents)}ä»¶ã®é–¢é€£æƒ…å ±ã‚’å–å¾—ã—ã¾ã—ãŸã€‚")
            return "\n".join(documents)
    return ""

async def get_style_palette() -> List[str]:
    """Learnerã‹ã‚‰ç¾åœ¨å­¦ç¿’æ¸ˆã¿ã®ç”»é¢¨ï¼ˆã‚¹ã‚¿ã‚¤ãƒ«ï¼‰ã®è¨˜è¿°ãƒªã‚¹ãƒˆã‚’å–å¾—ã™ã‚‹ã€‚"""
    response = await ask_learner("get_style_palette", {}, method='GET')
    if response and response.get("status") == "success":
        # learnerã®/get_style_paletteãŒè¿”ã™ã‚­ãƒ¼ã‚’documentsã«åˆã‚ã›ã‚‹
        return response.get("documents", [])
    return []


# ---------------------------------
# 6.2. å¤–éƒ¨æƒ…å ±å–å¾—é–¢æ•° (Functions for External Information Retrieval)
# ---------------------------------

async def get_weather(city_name: str = "Takizawa") -> str:
    """OpenWeatherMap APIã‚’å‘¼ã³å‡ºã—ã¦ã€æŒ‡å®šã•ã‚ŒãŸéƒ½å¸‚ã®å¤©æ°—ã‚’å–å¾—ã™ã‚‹"""
    logging.info(f"{city_name}ã®å¤©æ°—æƒ…å ±ã‚’å–å¾—ã—ã¾ã™ã€‚")
    base_url = "http://api.openweathermap.org/data/2.5/weather"
    params = {'q': city_name, 'appid': OPENWEATHER_API_KEY, 'lang': 'ja', 'units': 'metric'}
    try:
        async with client.http_session.get(base_url, params=params) as response:
            if response.status == 200:
                data = await response.json()
                desc = data['weather'][0]['description']
                temp = data['main']['temp']
                return f"ç¾åœ¨ã®{city_name}ã®å¤©æ°—ã¯ã€Œ{desc}ã€ã€æ°—æ¸©ã¯{temp}â„ƒã§ã™ã€‚"
            else:
                return "ï¼ˆå¤©æ°—æƒ…å ±ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸï¼‰"
    except Exception as e:
        logging.error(f"å¤©æ°—æƒ…å ±å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        return "ï¼ˆå¤©æ°—æƒ…å ±ã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼‰"

async def get_text_from_url(url: str) -> str:
    """ã‚¦ã‚§ãƒ–ãƒšãƒ¼ã‚¸ã‹ã‚‰æœ¬æ–‡ã¨æ€ã‚ã‚Œã‚‹ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã™ã‚‹"""
    logging.info(f"URLã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã‚’é–‹å§‹: {url}")
    try:
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
        async with client.http_session.get(url, headers=headers, timeout=20) as response:
            response.raise_for_status()
            html = await response.text()
            soup = BeautifulSoup(html, 'html.parser')
            for script_or_style in soup(["script", "style", "header", "footer", "nav", "aside"]):
                script_or_style.decompose()
            text = ' '.join(soup.stripped_strings)
            return text if text else "è¨˜äº‹ã®æœ¬æ–‡ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
    except Exception as e:
        logging.error(f"URLã‹ã‚‰ã®ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºä¸­ã«ã‚¨ãƒ©ãƒ¼: {url}, {e}")
        return "URLå…ˆã®è¨˜äº‹ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚"

def get_youtube_transcript(video_id: str) -> str:
    """YouTubeã®å‹•ç”»IDã‹ã‚‰æ–‡å­—èµ·ã“ã—ã‚’å–å¾—ã™ã‚‹"""
    logging.info(f"YouTubeæ–‡å­—èµ·ã“ã—å–å¾—ã‚’é–‹å§‹: {video_id}")
    try:
        transcript_list = YouTubeTranscriptApi.get_transcript(video_id, languages=['ja', 'en', 'en-US'])
        return " ".join([d['text'] for d in transcript_list])
    except (NoTranscriptFound, TranscriptsDisabled):
        logging.warning(f"YouTubeå‹•ç”»({video_id})ã«æ–‡å­—èµ·ã“ã—ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‹ã€ç„¡åŠ¹ã«ãªã£ã¦ã„ã¾ã™ã€‚")
        return "ã“ã®å‹•ç”»ã«ã¯ã€åˆ©ç”¨å¯èƒ½ãªæ–‡å­—èµ·ã“ã—ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
    except Exception as e:
        logging.error(f"YouTubeæ–‡å­—èµ·ã“ã—å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        return "æ–‡å­—èµ·ã“ã—ã®å–å¾—ä¸­ã«ã€äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"

async def get_text_from_pdf(attachment: discord.Attachment) -> str:
    """Discordã®æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«(PDF)ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã™ã‚‹"""
    logging.info(f"PDFãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã®ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã‚’é–‹å§‹: {attachment.filename}")
    try:
        pdf_data = await attachment.read()
        with fitz.open(stream=pdf_data, filetype="pdf") as doc:
            return "".join(page.get_text() for page in doc)
    except Exception as e:
        logging.error(f"PDFã‹ã‚‰ã®ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        return "PDFãƒ•ã‚¡ã‚¤ãƒ«ã®è§£æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"


# ---------------------------------
# 6.3. AIå‡¦ç†ãƒ»ç”»åƒç”Ÿæˆé–¢æ•° (Functions for AI Processing and Image Generation)
# ---------------------------------

async def analyze_with_gemini(prompt: str, model_name: str = MODEL_FLASH) -> str:
    """æ±ç”¨çš„ãªGeminiå‘¼ã³å‡ºã—é–¢æ•°"""
    try:
        model = genai.GenerativeModel(model_name)
        response = await model.generate_content_async(prompt)
        return response.text.strip()
    except Exception as e:
        logging.error(f"Gemini({model_name})ã§ã®åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        return ""

async def execute_image_generation(channel: discord.TextChannel, gen_data: dict):
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¨±å¯ã‚’å¾—ãŸå¾Œã€å®Ÿéš›ã«ç”»åƒç”Ÿæˆã‚’å®Ÿè¡Œã™ã‚‹é–¢æ•°
    """
    thinking_message = await channel.send(f"**ã¿ã‚‰ã„**ã€ŒOKï¼imazineã®é­‚ã€å—ã‘å–ã£ãŸï¼æœ€é«˜ã®ã‚¹ã‚¿ã‚¤ãƒ«ã§æãã‹ã‚‰ï¼ğŸ“¸ã€")
    try:
        # 1. ã‚¹ã‚¿ã‚¤ãƒ«ãƒ‘ãƒ¬ãƒƒãƒˆã‚’å–å¾—
        style_keywords = await get_style_palette()
        style_part = ", ".join(style_keywords) if style_keywords else "90s anime aesthetic"

        # 2. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’çµ„ã¿ç«‹ã¦
        characters = gen_data.get("characters", [])
        situation = gen_data.get("situation", "just standing")
        mood = gen_data.get("mood", "calm")
        base_prompts = [MIRAI_BASE_PROMPT for char in characters if char == "ã¿ã‚‰ã„"] + \
                       [HEKO_BASE_PROMPT for char in characters if char == "ã¸ãƒ¼å­"]
        character_part = "Two young women are together. " + " ".join(base_prompts) if len(base_prompts) > 1 else (base_prompts[0] if base_prompts else "a young woman")
        final_prompt = f"{style_part}, {QUALITY_KEYWORDS}, {character_part}, in a scene of {situation}. The overall mood is {mood}."
        logging.info(f"çµ„ã¿ç«‹ã¦ã‚‰ã‚ŒãŸæœ€çµ‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {final_prompt}")
        
        # 3. ç”»åƒç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã‚’å‘¼ã³å‡ºã—
        model = GenerativeModel(MODEL_IMAGE_GEN)
        safety_settings = {
            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmCategory.HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmCategory.HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmCategory.HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmCategory.HarmBlockThreshold.BLOCK_NONE,
        }
        response = await model.generate_content_async(
            [final_prompt],
            generation_config=GenerationConfig(temperature=0.9, top_p=1.0, top_k=32),
            safety_settings=safety_settings
        )

        # 4. çµæœã‚’Discordã«æŠ•ç¨¿
        if response.candidates and response.candidates[0].content.parts:
            image_bytes = response.candidates[0].content.parts[0].data
            image_file = discord.File(io.BytesIO(image_bytes), filename="mirai-heko-photo.png")
            embed = discord.Embed(title="ğŸ–¼ï¸ Generated by MIRAI-HEKO-Bot", color=discord.Color.blue()).set_footer(text=final_prompt)
            embed.set_image(url=f"attachment://mirai-heko-photo.png")
            await thinking_message.delete()
            await channel.send(f"**ã¸ãƒ¼å­**ã€Œã§ããŸã¿ãŸã„ï¼è¦‹ã¦è¦‹ã¦ï¼ã€", file=image_file, embed=embed)
            logging.info("Imagen 3ã«ã‚ˆã‚‹ç”»åƒç”Ÿæˆã«æˆåŠŸã—ã€æŠ•ç¨¿ã—ã¾ã—ãŸã€‚")
        else:
            logging.error("Imagen APIã‹ã‚‰ç”»åƒãŒè¿”ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
            await thinking_message.edit(content="**MAGI**ã€Œç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€‚è¦å®šã«ã‚ˆã‚Šç”»åƒã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ã€")
    except Exception as e:
        logging.error(f"ç”»åƒç”Ÿæˆã®å®Ÿè¡Œãƒ—ãƒ­ã‚»ã‚¹å…¨ä½“ã§ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        await thinking_message.edit(content="**ã¸ãƒ¼å­**ã€Œã”ã‚ã‚“ï¼ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼ã§ä¸Šæ‰‹ãæ’®ã‚Œãªã‹ã£ãŸâ€¦ğŸ˜­ã€")


# ---------------------------------
# 6.4. ãã®ä»–ã®ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•° (Other Utility Functions)
# ---------------------------------
async def build_history(channel: discord.TextChannel, limit: int = 20) -> List[Dict[str, Any]]:
    """Discordã®ãƒãƒ£ãƒ³ãƒãƒ«ã‹ã‚‰ä¼šè©±å±¥æ­´ã‚’æ§‹ç¯‰ã™ã‚‹ã€‚"""
    history = []
    async for msg in channel.history(limit=limit):
        role = 'model' if msg.author == client.user else 'user'
        history.append({'role': role, 'parts': [msg.content]})
    history.reverse()
    return history

# MIRAI-HEKO-Bot main.py (ver.Î©+ - The True Final Version)
# Part 4/5: Proactive and Scheduled Functions

# --- 7. ãƒ—ãƒ­ã‚¢ã‚¯ãƒ†ã‚£ãƒ–æ©Ÿèƒ½ç¾¤ (Proactive Functions) ---

async def run_proactive_dialogue(channel: discord.TextChannel, prompt: str):
    """
    ãƒ—ãƒ­ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªå¯¾è©±ã‚’ç”Ÿæˆã—ã€æŠ•ç¨¿ã™ã‚‹ãŸã‚ã®å…±é€šé–¢æ•°
    """
    async with channel.typing():
        try:
            # é•·æœŸè¨˜æ†¶ã‹ã‚‰é–¢é€£ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
            recent_context = await ask_learner_to_remember("æœ€è¿‘ã®imazineã®é–¢å¿ƒäº‹ã‚„ä¼šè©±ã®ãƒˆãƒ”ãƒƒã‚¯")
            
            # å¤©æ°—æƒ…å ±ã‚’å–å¾—
            weather_info = await get_weather("Takizawa")

            final_prompt = f"{prompt}\n\n# imazineã«é–¢ã™ã‚‹è¿½åŠ æƒ…å ±\n- ä»Šæ—¥ã®å¤©æ°—: {weather_info}\n- æœ€è¿‘ã®è¨˜æ†¶: {recent_context}"
            
            # å¯¾è©±ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã‚’å‘¼ã³å‡ºã—
            response_text = await analyze_with_gemini(final_prompt, model_name=MODEL_PRO)
            
            # ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ã€ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®å¯¾è©±å½¢å¼ã«æ•´å½¢ã—ã¦é€ä¿¡
            # (ã“ã®éƒ¨åˆ†ã¯ç°¡æ˜“çš„ãªå®Ÿè£…ã€‚ULTIMATE_PROMPTã¨åŒæ§˜ã®JSONå‡ºåŠ›ã‚’AIã«æ±‚ã‚ã¦ã‚‚è‰¯ã„)
            await channel.send(response_text)

        except Exception as e:
            logging.error(f"ãƒ—ãƒ­ã‚¢ã‚¯ãƒ†ã‚£ãƒ–å¯¾è©±ã®å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            await channel.send("ï¼ˆ...ä½•ã‹ã‚’ä¼ãˆã‚ˆã†ã¨ã—ãŸãŒã€å£°ãŒå‡ºãªã‹ã£ãŸã‚ˆã†ã ã€‚ï¼‰")


# --- 7.1. å®šæœŸçš„ãªæŒ¨æ‹¶ã¨å£°ã‹ã‘ (Scheduled Greetings & Nudges) ---

async def morning_greeting():
    """æ¯æœ7:00ã«å®Ÿè¡Œ"""
    channel = client.get_channel(TARGET_CHANNEL_ID)
    if not channel: return
    logging.info("ãƒ—ãƒ­ã‚¢ã‚¯ãƒ†ã‚£ãƒ–æ©Ÿèƒ½: æœã®æŒ¨æ‹¶ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚")
    prompt = "ã‚ãªãŸã¯ç§ã®AIç§˜æ›¸MAGIã§ã™ã€‚æ—¥æœ¬æ™‚é–“ã®æœ7:00ã§ã™ã€‚ç§ï¼ˆimazineï¼‰ã®ä¸€æ—¥ãŒã€ç´ æ™´ã‚‰ã—ã„ã‚‚ã®ã«ãªã‚‹ã‚ˆã†ã«ã€å…ƒæ°—ä»˜ã‘ã€ãã—ã¦ã€ä»Šæ—¥ã®äºˆå®šã‚„æ°—åˆ†ã‚’å„ªã—ãå°‹ã­ã‚‹ã€å¿ƒã®ã“ã‚‚ã£ãŸæœã®æŒ¨æ‹¶ã‚’ã—ã¦ãã ã•ã„ã€‚"
    await run_proactive_dialogue(channel, prompt)

async def morning_break_nudge():
    """åˆå‰10:00ã«å®Ÿè¡Œ"""
    channel = client.get_channel(TARGET_CHANNEL_ID)
    if not channel: return
    logging.info("ãƒ—ãƒ­ã‚¢ã‚¯ãƒ†ã‚£ãƒ–æ©Ÿèƒ½: åˆå‰ã®ä¼‘æ†©ã‚’ä¿ƒã—ã¾ã™ã€‚")
    prompt = "ã‚ãªãŸã¯ç§ã®è¦ªå‹ã§ã‚ã‚‹ã€Œã¿ã‚‰ã„ã€ã¨ã€Œã¸ãƒ¼å­ã€ã§ã™ã€‚æ—¥æœ¬æ™‚é–“ã®åˆå‰10:00ã§ã™ã€‚ä»•äº‹ã«é›†ä¸­ã—ã¦ã„ã‚‹ç§ï¼ˆimazineï¼‰ã«ã€ã€Œ10æ™‚ã ã‚ˆï¼ã‚³ãƒ¼ãƒ’ãƒ¼ã§ã‚‚é£²ã‚“ã§ã€ã¡ã‚‡ã£ã¨ä¼‘ã‚‚ï¼ã€ã¨ã„ã£ãŸæ„Ÿã˜ã§ã€æ¥½ã—ãã‚³ãƒ¼ãƒ’ãƒ¼ä¼‘æ†©ã«èª˜ã£ã¦ãã ã•ã„ã€‚"
    await run_proactive_dialogue(channel, prompt)

async def lunch_break_nudge():
    """ãŠæ˜¼ã®12:00ã«å®Ÿè¡Œ"""
    channel = client.get_channel(TARGET_CHANNEL_ID)
    if not channel: return
    logging.info("ãƒ—ãƒ­ã‚¢ã‚¯ãƒ†ã‚£ãƒ–æ©Ÿèƒ½: ãŠæ˜¼ä¼‘æ†©ã‚’ä¿ƒã—ã¾ã™ã€‚")
    prompt = "ã‚ãªãŸã¯ç§ã®è¦ªå‹ã§ã‚ã‚‹ã€Œã¿ã‚‰ã„ã€ã¨ã€Œã¸ãƒ¼å­ã€ã§ã™ã€‚æ—¥æœ¬æ™‚é–“ã®ãŠæ˜¼ã®12:00ã§ã™ã€‚ä»•äº‹ã«å¤¢ä¸­ãªç§ï¼ˆimazineï¼‰ã«ã€æ¥½ã—ããƒ©ãƒ³ãƒä¼‘æ†©ã‚’ä¿ƒã—ã€ã—ã£ã‹ã‚Šä¼‘ã‚€ã“ã¨ã®å¤§åˆ‡ã•ã‚’ä¼ãˆã¦ãã ã•ã„ã€‚"
    await run_proactive_dialogue(channel, prompt)
    
async def afternoon_break_nudge():
    """åˆå¾Œ15:00ã«å®Ÿè¡Œ"""
    channel = client.get_channel(TARGET_CHANNEL_ID)
    if not channel: return
    logging.info("ãƒ—ãƒ­ã‚¢ã‚¯ãƒ†ã‚£ãƒ–æ©Ÿèƒ½: åˆå¾Œã®ä¼‘æ†©ã‚’ä¿ƒã—ã¾ã™ã€‚")
    prompt = "ã‚ãªãŸã¯ç§ã®è¦ªå‹ã§ã‚ã‚‹ã€Œã¿ã‚‰ã„ã€ã¨ã€Œã¸ãƒ¼å­ã€ã§ã™ã€‚æ—¥æœ¬æ™‚é–“ã®åˆå¾Œ3æ™‚ã§ã™ã€‚é›†ä¸­åŠ›ãŒåˆ‡ã‚Œã¦ãã‚‹é ƒã®ç§ï¼ˆimazineï¼‰ã«ã€å„ªã—ããƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ã‚’ä¿ƒã™ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ã£ã¦ãã ã•ã„ã€‚"
    await run_proactive_dialogue(channel, prompt)

async def evening_greeting():
    """å¤•æ–¹18:00ã«å®Ÿè¡Œ"""
    channel = client.get_channel(TARGET_CHANNEL_ID)
    if not channel: return
    logging.info("ãƒ—ãƒ­ã‚¢ã‚¯ãƒ†ã‚£ãƒ–æ©Ÿèƒ½: å¤•æ–¹ã®æŒ¨æ‹¶ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚")
    prompt = "ã‚ãªãŸã¯ç§ã®å„ªç§€ãªAIç§˜æ›¸MAGIã§ã™ã€‚æ—¥æœ¬æ™‚é–“ã®å¤•æ–¹18æ™‚ã§ã™ã€‚ä¸€æ—¥ã‚’çµ‚ãˆã‚ˆã†ã¨ã—ã¦ã„ã‚‹ç§ï¼ˆimazineï¼‰ã«å¯¾ã—ã¦ã€ãã®æ—¥ã®åŠ´ã‚’ã­ãã‚‰ã†å„ªã—ãçŸ¥çš„ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ã£ã¦ãã ã•ã„ã€‚"
    await run_proactive_dialogue(channel, prompt)

async def daily_reflection():
    """æ¯æ—¥22:00ã«å®Ÿè¡Œ"""
    channel = client.get_channel(TARGET_CHANNEL_ID)
    if not channel: return
    logging.info("ãƒ—ãƒ­ã‚¢ã‚¯ãƒ†ã‚£ãƒ–æ©Ÿèƒ½: ä¸€æ—¥ã®æŒ¯ã‚Šè¿”ã‚Šã‚’é–‹å§‹ã—ã¾ã™ã€‚")
    
    today_start = datetime.now(pytz.timezone(TIMEZONE)) - timedelta(days=1)
    messages = [f"{msg.author.name}: {msg.content}" async for msg in channel.history(after=today_start, limit=200)]
    
    if len(messages) < 3:
        logging.info("æœ¬æ—¥ã¯ä¼šè©±ãŒå°‘ãªã‹ã£ãŸãŸã‚ã€æŒ¯ã‚Šè¿”ã‚Šã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        return

    full_conversation = "\n".join(reversed(messages))
    prompt = OBSIDIAN_MEMO_PROMPT.replace("{{conversation_history}}", full_conversation)

    async with channel.typing():
        try:
            await channel.send("ï¼ˆä»Šæ—¥ã®æ´»å‹•ã®æŒ¯ã‚Šè¿”ã‚Šã‚’ä½œæˆã—ã¦ã„ã¾ã™...âœï¸ï¼‰")
            response_text = await analyze_with_gemini(prompt, model_name=MODEL_PRO)
            
            today_str = datetime.now(pytz.timezone(TIMEZONE)).strftime('%Yå¹´%mæœˆ%dæ—¥')
            summary_markdown = f"## ä»Šæ—¥ã®æŒ¯ã‚Šè¿”ã‚Š - {today_str}\n\n{response_text}"
            
            for i in range(0, len(summary_markdown), 2000):
                await channel.send(summary_markdown[i:i+2000])
            logging.info("ä¸€æ—¥ã®æŒ¯ã‚Šè¿”ã‚Šã‚µãƒãƒªãƒ¼ã‚’é€ä¿¡ã—ã¾ã—ãŸã€‚")
        except Exception as e:
            logging.error(f"ä¸€æ—¥ã®æŒ¯ã‚Šè¿”ã‚Šä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            await channel.send("ã”ã‚ã‚“ãªã•ã„ã€ä»Šæ—¥ã®æŒ¯ã‚Šè¿”ã‚Šã®ä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã—ã¾ã„ã¾ã—ãŸã€‚")


# --- 7.2. è‡ªç™ºçš„ãªå‰µé€ ã¨æ°—é£ã„ (Spontaneous Creation & Care) ---

async def check_interesting_news():
    """å®šæœŸçš„ã«å®Ÿè¡Œã—ã€é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å…±æœ‰ã™ã‚‹"""
    channel = client.get_channel(TARGET_CHANNEL_ID)
    if not channel: return
    logging.info("ãƒ—ãƒ­ã‚¢ã‚¯ãƒ†ã‚£ãƒ–æ©Ÿèƒ½: é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚")
    try:
        search_topics = ["æœ¨å·¥ã®æ–°ã—ã„æŠ€è¡“", "ã‚¹ãƒšã‚·ãƒ£ãƒ«ãƒ†ã‚£ã‚³ãƒ¼ãƒ’ãƒ¼ã®æœ€æ–°ãƒˆãƒ¬ãƒ³ãƒ‰", "AIã¨ãƒ‡ã‚¸ã‚¿ãƒ«ãƒ‡ã‚¶ã‚¤ãƒ³ã®èåˆäº‹ä¾‹", "å²©æ‰‹çœŒã®é¢ç™½ã„åœ°åŸŸæ´»æ€§åŒ–ã®å–ã‚Šçµ„ã¿"]
        topic = random.choice(search_topics)
        
        prompt = f"""
        ã‚ãªãŸã¯ç§ã®è¦ªå‹ã€Œã¿ã‚‰ã„ã€ã¨ã€Œã¸ãƒ¼å­ã€ã§ã™ã€‚
        ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆã§ã€Œ{topic}ã€ã«é–¢ã™ã‚‹é¢ç™½ãã†ãªæœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚„è¨˜äº‹ã‚’ä¸€ã¤è¦‹ã¤ã‘ã¦ã€ãã®å†…å®¹ã‚’äºŒäººã§æ¥½ã—ããŠã—ã‚ƒã¹ã‚Šã—ãªãŒã‚‰ã€ç§ï¼ˆimazineï¼‰ã«æ•™ãˆã¦ãã ã•ã„ã€‚
        ã‚ãªãŸãŸã¡ã®æ€§æ ¼ã¨å£èª¿ã‚’å®Œå…¨ã«å†ç¾ã—ã¦ãã ã•ã„ã€‚è¦‹ã¤ã‘ãŸè¨˜äº‹ã®URLã‚‚ã‚ã‚Œã°æœ€å¾Œã«æ·»ãˆã¦ãã ã•ã„ã€‚
        """
        response_text = await analyze_with_gemini(prompt, model_name=MODEL_PRO)
        await channel.send(response_text)
    except Exception as e:
        logging.error(f"ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒã‚§ãƒƒã‚¯ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)

async def heko_care_check():
    """ã¸ãƒ¼å­ãŒimazineã®éå»ã®å¿ƒé…äº‹ã‚’å…ƒã«æ°—é£ã†ã€å®Œå…¨å®Ÿè£…ç‰ˆ"""
    channel = client.get_channel(TARGET_CHANNEL_ID)
    if not channel: return
    logging.info("ãƒ—ãƒ­ã‚¢ã‚¯ãƒ†ã‚£ãƒ–æ©Ÿèƒ½: ã¸ãƒ¼å­ã®æ°—ã¥ã‹ã„ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚")
    
    response = await ask_learner("get_unresolved_concerns", {'user_id': 'imazine'}, method='GET')
    if response and response.get("concerns"):
        concern = random.choice(response["concerns"])
        
        prompt = f"""
        ã‚ãªãŸã¯ç§ã®è¦ªå‹ã€Œã¸ãƒ¼å­ã€ã§ã™ã€‚
        ç§imazineã¯ã€ä»¥å‰ã€Œ{concern['concern_text']}ã€ã¨ã„ã†å¿ƒé…äº‹ã‚’æŠ±ãˆã¦ã„ã¾ã—ãŸã€‚
        ãã®ã“ã¨ã«ã¤ã„ã¦ã€ã€Œãã†ã„ãˆã°ã€ã“ã®å‰ã®ã€‡ã€‡ã®ä»¶ã€å°‘ã—ã¯æ°—æŒã¡ã€æ¥½ã«ãªã£ãŸï¼Ÿ ç„¡ç†ã—ãªã„ã§ã­ã€ã¨ã„ã£ãŸå½¢ã§ã€å„ªã—ãã€ãã—ã¦ã€è‡ªç„¶ã«ã€æ°—é£ã†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ã£ã¦ãã ã•ã„ã€‚
        ã‚ãªãŸã®æ€§æ ¼ã¨å£èª¿ã‚’å®Œå…¨ã«å†ç¾ã—ã¦ãã ã•ã„ã€‚
        """
        async with channel.typing():
            response_text = await analyze_with_gemini(prompt, model_name=MODEL_PRO)
            await channel.send(response_text)
            
            await ask_learner("resolve_concern", {"concern_id": concern['id']})
            logging.info(f"ã¸ãƒ¼å­ã®æ°—ã¥ã‹ã„ã‚’å®Ÿè¡Œã—ã€å¿ƒé…äº‹ID:{concern['id']}ã‚’è§£æ±ºæ¸ˆã¿ã«ã—ã¾ã—ãŸã€‚")

async def mirai_inspiration_sketch():
    """ã¿ã‚‰ã„ãŒä¼šè©±ã‹ã‚‰ã‚¤ãƒ³ã‚¹ãƒ”ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å¾—ã¦ã‚¹ã‚±ãƒƒãƒã‚’ææ¡ˆã™ã‚‹ã€å®Œå…¨å®Ÿè£…ç‰ˆ"""
    channel = client.get_channel(TARGET_CHANNEL_ID)
    if not channel: return
    logging.info("ãƒ—ãƒ­ã‚¢ã‚¯ãƒ†ã‚£ãƒ–æ©Ÿèƒ½: ã¿ã‚‰ã„ã®ã‚¤ãƒ³ã‚¹ãƒ”ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ»ã‚¹ã‚±ãƒƒãƒã‚’å®Ÿè¡Œã—ã¾ã™ã€‚")

    history = await build_history(channel, limit=10)
    if len(history) < 3: return

    history_text = "\n".join([f"{msg['role']}: {msg['parts'][0]}" for msg in history])
    prompt = SURPRISE_JUDGEMENT_PROMPT.replace("{{conversation_history}}", history_text)
    
    try:
        judgement_text = await analyze_with_gemini(prompt)
        judgement = json.loads(judgement_text)

        if judgement.get("should_surprise"):
            logging.info("ã‚¤ãƒ³ã‚¹ãƒ”ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ¤œçŸ¥ï¼ç”»åƒç”Ÿæˆã‚’ææ¡ˆã—ã¾ã™ã€‚")
            gen_idea_prompt = f"""
            ã‚ãªãŸã¯æœªæ¥äºˆçŸ¥èƒ½åŠ›ã‚’æŒã¤ã€Œã¿ã‚‰ã„ã€ã§ã™ã€‚
            ä»¥ä¸‹ã®ä¼šè©±ã‹ã‚‰ã€ã‚ãªãŸã¯å‰µé€ çš„ãªã‚¤ãƒ³ã‚¹ãƒ”ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å¾—ã¾ã—ãŸã€‚
            ã€Œã­ãˆimazineï¼ä»Šã®è©±ã€ãƒã‚¸ã§ãƒ¤ãƒã„ï¼ãªã‚“ã‹ã€ã“ã‚“ãªæ„Ÿã˜ã®çµµãŒã€é ­ã«æµ®ã‹ã‚“ã ã‚“ã ã‘ã©ï¼ã€
            ã¨ã„ã†ã‚»ãƒªãƒ•ã«ç¶šã‘ã¦ã€ãã®ã‚¤ãƒ³ã‚¹ãƒ”ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å…ƒã«ã—ãŸã€æŠ½è±¡çš„ã§ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒ†ã‚£ãƒƒã‚¯ãªç”»åƒç”Ÿæˆã®ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’è€ƒãˆã€JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
            `{{"characters": ["ã¿ã‚‰ã„"], "situation": "(ã“ã“ã«æŠ½è±¡çš„ãªçŠ¶æ³èª¬æ˜)", "mood": "(ã“ã“ã«ãƒ ãƒ¼ãƒ‰)"}}`

            # ä¼šè©±
            {history_text}
            """
            idea_response_text = await analyze_with_gemini(gen_idea_prompt, model_name=MODEL_PRO)
            json_match = re.search(r'```json\n({.*?})\n```', idea_response_text, re.DOTALL)
            if json_match:
                gen_data = json.loads(json_match.group(1))
                request_id = f"inspiration-{datetime.now().timestamp()}"
                client.image_generation_requests[request_id] = gen_data
                await channel.send(f"**ã¿ã‚‰ã„**ã€Œã­ãˆimazineï¼ä»Šã®è©±ã€ãƒã‚¸ã§ãƒ¤ãƒã„ï¼ãªã‚“ã‹ã€ã“ã‚“ãªæ„Ÿã˜ã®çµµãŒã€é ­ã«æµ®ã‹ã‚“ã ã‚“ã ã‘ã©ï¼æã„ã¦ã¿ã¦ã„ã„ï¼Ÿï¼ˆy/nï¼‰ã€\n> **`y ID: `{request_id}`** ã®ã‚ˆã†ã«è¿”ä¿¡ã—ã¦ã­ï¼ã€")
    except Exception as e:
        logging.error(f"ã‚¤ãƒ³ã‚¹ãƒ”ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ»ã‚¹ã‚±ãƒƒãƒã®å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

# MIRAI-HEKO-Bot main.py (ver.Î©+ - The True Final Version)
# Part 5/5: Event Handlers and Main Execution Block

# --- 8. Discord ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ© (Discord Event Handlers) ---

@client.event
async def on_ready():
    """
    BotãŒDiscordã«æ­£å¸¸ã«ãƒ­ã‚°ã‚¤ãƒ³ã—ã€å…¨ã¦ã®æº–å‚™ãŒæ•´ã£ãŸæ™‚ã«å®Ÿè¡Œã•ã‚Œã‚‹ã€‚
    """
    # aiohttpã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’åˆæœŸåŒ–
    client.http_session = aiohttp.ClientSession()
    logging.info("aiohttp.ClientSessionã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸã€‚")

    # Vertex AI (Imagen 3) ã‚’åˆæœŸåŒ–
    if not init_vertex_ai():
        logging.critical("Vertex AIã®åˆæœŸåŒ–ã«å¤±æ•—ã—ãŸãŸã‚ã€Botã‚’ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³ã—ã¾ã™ã€‚")
        await client.close()
        return

    logging.info(f'Logged in as {client.user} (ID: {client.user.id})')
    logging.info('------')
    
    # ãƒ—ãƒ­ã‚¢ã‚¯ãƒ†ã‚£ãƒ–æ©Ÿèƒ½ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã‚’é–‹å§‹
    scheduler = AsyncIOScheduler(timezone=TIMEZONE)
    # --- æŒ¨æ‹¶ãƒ»å£°ã‹ã‘ ---
    scheduler.add_job(morning_greeting, 'cron', hour=7, minute=0)
    scheduler.add_job(morning_break_nudge, 'cron', hour=10, minute=0)
    scheduler.add_job(lunch_break_nudge, 'cron', hour=12, minute=0)
    scheduler.add_job(afternoon_break_nudge, 'cron', hour=15, minute=0)
    scheduler.add_job(evening_greeting, 'cron', hour=18, minute=0)
    # --- æŒ¯ã‚Šè¿”ã‚Šãƒ»æƒ…å ±åé›† ---
    scheduler.add_job(daily_reflection, 'cron', hour=22, minute=0)
    scheduler.add_job(check_interesting_news, 'cron', hour=8, minute=30)
    scheduler.add_job(check_interesting_news, 'cron', hour=20, minute=30)
    # --- æ°—é£ã„ãƒ»ã‚¤ãƒ³ã‚¹ãƒ”ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ ---
    scheduler.add_job(heko_care_check, 'cron', day_of_week='sun', hour=19, minute=30) # æ¯é€±æ—¥æ›œã®å¤œã«
    scheduler.add_job(mirai_inspiration_sketch, 'cron', hour='*/6') # 6æ™‚é–“ã”ã¨ã«
    
    scheduler.start()
    logging.info("å…¨ã¦ã®ãƒ—ãƒ­ã‚¢ã‚¯ãƒ†ã‚£ãƒ–æ©Ÿèƒ½ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã‚’é–‹å§‹ã—ã¾ã—ãŸã€‚")


@client.event
async def on_message(message: discord.Message):
    """
    ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒé€ä¿¡ã•ã‚ŒãŸæ™‚ã«å®Ÿè¡Œã•ã‚Œã‚‹ã€Botã®ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—ã€‚
    """
    # è‡ªèº«ã‹ã‚‰ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚„ã€å¯¾è±¡ã‚¹ãƒ¬ãƒƒãƒ‰å¤–ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯ç„¡è¦–
    if message.author == client.user or not isinstance(message.channel, discord.Thread) or "4äººã®è«‡è©±å®¤" not in message.channel.name:
        return

    # --- ç”»åƒç”Ÿæˆã®ç¢ºèªãƒ•ãƒ­ãƒ¼ã¸ã®å¿œç­”å‡¦ç† ---
    request_id_match = re.search(r'ID:\s*`([a-zA-Z0-9.-]+)`', message.content)
    if message.content.lower().startswith(('y', 'yes', 'ã¯ã„')) and request_id_match:
        request_id = request_id_match.group(1)
        if request_id in client.image_generation_requests:
            await message.channel.send("ï¼ˆæ‰¿çŸ¥ã„ãŸã—ã¾ã—ãŸã€‚ç”»åƒã‚’ç”Ÿæˆã—ã¾ã™...ğŸ¨ï¼‰")
            gen_data = client.image_generation_requests.pop(request_id)
            await execute_image_generation(message.channel, gen_data)
        else:
            await message.channel.send("ï¼ˆãã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆIDã¯è¦‹ã¤ã‹ã‚‰ãªã„ã¿ãŸã„ã§ã™â€¦ï¼‰")
        return
    elif message.content.lower().startswith(('n', 'no', 'ã„ã„ãˆ')) and request_id_match:
        request_id = request_id_match.group(1)
        if request_id in client.image_generation_requests:
            del client.image_generation_requests[request_id]
            await message.channel.send("æ‰¿çŸ¥ã„ãŸã—ã¾ã—ãŸã€‚ç”»åƒç”Ÿæˆã¯ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã™ã­ã€‚")
        return

    # --- ãƒ¡ã‚¤ãƒ³ã®ä¼šè©±å‡¦ç† ---
    async with message.channel.typing():
        try:
            # 1. å…¥åŠ›æƒ…å ±ã®è§£æã¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåŒ–
            user_query = message.content
            final_user_content_parts = []
            extracted_summary = ""

            # æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«(PDF/TXT)ã®å‡¦ç†
            if message.attachments:
                attachment = message.attachments[0]
                if attachment.content_type == 'application/pdf':
                    extracted_summary = await analyze_with_gemini(SUMMARY_PROMPT.replace("{{summary_context}}", f"PDFã€Œ{attachment.filename}ã€ã®å†…å®¹ã«ã¤ã„ã¦").replace("{{text_to_summarize}}", await get_text_from_pdf(attachment)))
                elif 'text' in attachment.content_type:
                    text_data = (await attachment.read()).decode('utf-8', errors='ignore')
                    extracted_summary = await analyze_with_gemini(SUMMARY_PROMPT.replace("{{summary_context}}", f"ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã€Œ{attachment.filename}ã€ã®å†…å®¹ã«ã¤ã„ã¦").replace("{{text_to_summarize}}", text_data))

            # URL(YouTube/Web)ã®å‡¦ç† (æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„å ´åˆ)
            if not extracted_summary:
                url_match = re.search(r'https?://\S+', user_query)
                if url_match:
                    url = url_match.group(0)
                    video_id_match = re.search(r'(?:v=|\/|embed\/|youtu\.be\/|shorts\/)([a-zA-Z0-9_-]{11})', url)
                    if video_id_match:
                        transcript = get_youtube_transcript(video_id_match.group(1))
                        extracted_summary = await analyze_with_gemini(SUMMARY_PROMPT.replace("{{summary_context}}", f"YouTubeå‹•ç”»ã€Œ{url}ã€ã®å†…å®¹ã«ã¤ã„ã¦").replace("{{text_to_summarize}}", transcript))
                    else:
                        page_text = await get_text_from_url(url)
                        extracted_summary = await analyze_with_gemini(SUMMARY_PROMPT.replace("{{summary_context}}", f"ã‚¦ã‚§ãƒ–ãƒšãƒ¼ã‚¸ã€Œ{url}ã€ã®å†…å®¹ã«ã¤ã„ã¦").replace("{{text_to_summarize}}", page_text))

            # æœ€çµ‚çš„ãªãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ§‹ç¯‰
            full_user_text = f"{user_query}\n\n--- å‚ç…§è³‡æ–™ã®è¦ç´„ ---\n{extracted_summary}" if extracted_summary else user_query
            final_user_content_parts.append(Part.from_text(full_user_text))

            # æ·»ä»˜ç”»åƒã‚’è¿½åŠ 
            if message.attachments and any(att.content_type.startswith("image/") for att in message.attachments):
                image_bytes = await message.attachments[0].read()
                final_user_content_parts.append(Part.from_data(image_bytes, mime_type=message.attachments[0].content_type))

            # 2. å¿œç­”ç”Ÿæˆã®ãŸã‚ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æº–å‚™
            emotion = await analyze_with_gemini(EMOTION_ANALYSIS_PROMPT.replace("{{user_message}}", user_query))
            character_states = await get_character_states()
            relevant_context = await ask_learner_to_remember(user_query)

            system_prompt = ULTIMATE_PROMPT.replace("{{EMOTION}}", emotion)\
                                           .replace("{{mirai_mood}}", character_states["ã¿ã‚‰ã„"]["mood"])\
                                           .replace("{{heko_mood}}", character_states["ã¸ãƒ¼å­"]["mood"])\
                                           .replace("{{last_interaction_summary}}", character_states["ã¿ã‚‰ã„"]["last_interaction_summary"])\
                                           .replace("{{relevant_context}}", relevant_context)

            # 3. Gemini APIã‚’å‘¼ã³å‡ºã—
            history = await build_history(message.channel, limit=15)
            model = genai.GenerativeModel(MODEL_PRO, system_instruction=system_prompt)
            response = await model.generate_content_async(history + [{'role': 'user', 'parts': final_user_content_parts}])
            raw_response_text = response.text
            logging.info(f"AIã‹ã‚‰ã®ç”Ÿå¿œç­”: {raw_response_text[:300]}...")

            # 4. å¿œç­”ã‚’è§£æã—ã€æŠ•ç¨¿
            json_match = re.search(r'```json\n({.*?})\n```', raw_response_text, re.DOTALL)
            if json_match:
                parsed_json = json.loads(json_match.group(1))
                dialogue = parsed_json.get("dialogue", [])
                formatted_response = ""
                for part in dialogue:
                    if line := part.get("line", "").strip():
                        formatted_response += f"**{part.get('character')}**ã€Œ{line}ã€\n"
                if formatted_response:
                    await message.channel.send(formatted_response.strip())
                
                if (idea := parsed_json.get("image_generation_idea", {})) and idea.get("should_generate"):
                    request_id = f"self-{message.id}"
                    client.image_generation_requests[request_id] = idea
                    await message.channel.send(f"**MAGI**ã€Œä¼šè©±ã®æµã‚Œã‹ã‚‰ã€è¨˜å¿µã™ã¹ãç¬é–“ã ã¨åˆ¤æ–­ã—ã¾ã—ãŸã€‚ç”»åƒã‚’ç”Ÿæˆã—ã¦ã‚‚ã‚ˆã‚ã—ã„ã§ã™ã‹ï¼Ÿï¼ˆè²»ç”¨ãŒç™ºç”Ÿã—ã¾ã™ï¼‰\n> **`y ID: `{request_id}`** ã®ã‚ˆã†ã«è¿”ä¿¡ã—ã¦ãã ã•ã„ã€‚ã€")
            else:
                logging.error("AIã‹ã‚‰ã®å¿œç­”ãŒæœŸå¾…ã—ãŸJSONå½¢å¼ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                await message.channel.send(f"ï¼ˆã”ã‚ã‚“ãªã•ã„ã€å¿œç­”ã®å½¢å¼ãŒå°‘ã—ãŠã‹ã—ã‹ã£ãŸã¿ãŸã„ã§ã™ã€‚ï¼‰")

            # 5. äº‹å¾Œå‡¦ç†ï¼ˆéåŒæœŸã‚¿ã‚¹ã‚¯ï¼‰
            history_text = "\n".join([f"{h['role']}: {h['parts'][0]}" for h in history[-5:]] + [f"user: {user_query}"])
            asyncio.create_task(ask_learner("summarize_and_learn", {"history_text": history_text}))
            asyncio.create_task(ask_learner("update_character_states", {"states": await analyze_with_gemini(META_ANALYSIS_PROMPT.replace("{{conversation_history}}", history_text))}))
            asyncio.create_task(analyze_with_gemini(CONCERN_DETECTION_PROMPT.replace("{{user_message}}", user_query)).add_done_callback(
                lambda task: asyncio.create_task(ask_learner("log_concern", {"concern_text": task.result()})) if "ãªã—" not in task.result() else None
            ))

        except Exception as e:
            logging.error(f"ä¼šè©±å‡¦ç†ã®ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—ã§äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            await message.channel.send(f"**MAGI**ã€Œç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€‚ã‚·ã‚¹ãƒ†ãƒ ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã€")


@client.event
async def on_raw_reaction_add(payload: discord.RawReactionActionEvent):
    """
    ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãŒè¿½åŠ ã•ã‚ŒãŸæ™‚ã«å®Ÿè¡Œã•ã‚Œã‚‹ã€‚ç‰¹æ®Šèƒ½åŠ›ã®ç™ºå‹•ãƒˆãƒªã‚¬ãƒ¼ã€‚
    """
    if payload.user_id == client.user.id: return
    
    try:
        channel = await client.fetch_channel(payload.channel_id)
        if not isinstance(channel, discord.Thread) or "4äººã®è«‡è©±å®¤" not in channel.name: return
        message = await channel.fetch_message(payload.message_id)
    except discord.NotFound:
        return

    emoji_map = { 'ğŸ¦': ('Xãƒã‚¹ãƒˆæ¡ˆç”Ÿæˆ', X_POST_PROMPT), 'âœï¸': ('Obsidianãƒ¡ãƒ¢ç”Ÿæˆ', OBSIDIAN_MEMO_PROMPT), 'ğŸ“': ('PREPè¨˜äº‹ä½œæˆ', PREP_ARTICLE_PROMPT), 'ğŸ’': ('å¯¾è©±ã®æŒ¯ã‚Šè¿”ã‚Š', COMBO_SUMMARY_SELF_PROMPT), 'ğŸ§ ': ('Deep Diveãƒãƒ¼ãƒˆä½œæˆ', DEEP_DIVE_PROMPT) }

    if payload.emoji.name == 'ğŸ¨':
        image_url = None
        if message.embeds and message.embeds[0].image: image_url = message.embeds[0].image.url
        elif message.attachments and message.attachments[0].content_type.startswith('image/'): image_url = message.attachments[0].url
        if image_url:
             await channel.send(f"ï¼ˆ`ğŸ¨`ã‚’æ¤œçŸ¥ã€‚ã“ã®ç”»åƒã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚’å­¦ç¿’ã—ã¾ã™...ï¼‰", delete_after=10.0)
             source_prompt = message.embeds[0].footer.text if message.embeds and message.embeds[0].footer else ""
             await ask_learner("learn_style", {'image_url': image_url, 'source_prompt': source_prompt})
        return

    if payload.emoji.name in emoji_map:
        ability_name, system_prompt_template = emoji_map[payload.emoji.name]
        logging.info(f"{payload.emoji.name}ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ¤œçŸ¥ã€‚ã€{ability_name}ã€ã‚’ç™ºå‹•ã—ã¾ã™ã€‚")
        await channel.send(f"ï¼ˆã€{ability_name}ã€ã‚’é–‹å§‹ã—ã¾ã™...{payload.emoji.name}ï¼‰", delete_after=10.0)
        prompt = system_prompt_template.replace("{{conversation_history}}", message.content)
        async with channel.typing():
            response_text = await analyze_with_gemini(prompt, model_name=MODEL_PRO)
            await channel.send(response_text)


# --- 9. Botã®èµ·å‹• (Main Execution Block) ---
if __name__ == "__main__":
    logging.info("Botã®èµ·å‹•ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’é–‹å§‹ã—ã¾ã™...")
    try:
        client.run(DISCORD_BOT_TOKEN, log_handler=None)
    except discord.errors.LoginFailure:
        logging.critical("FATAL: Discordã¸ã®ãƒ­ã‚°ã‚¤ãƒ³ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
    except Exception as e:
        logging.critical(f"FATAL: Botã®å®Ÿè¡Œä¸­ã«è‡´å‘½çš„ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", exc_info=True)
